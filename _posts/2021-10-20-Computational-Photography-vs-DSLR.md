---
layout: post
title: Computational smartphone photography vs DSLR/Mirrorless
image: images/computationalPhotography/cp.jpeg
categories:
- Photography
---

![pic]({{ site.baseurl }}/images/computationalPhotography/cp.jpeg)

Many photographers do not realise that smartphone photos might actually produce better pictures than your good old DSLR. While a smartphone might not have very 'sharp' photos (due to small sensors and lenses) they tend to produce shots that are considered to be 'nicer' to the average person. This is because modern smartphones uses many software tricks which make a picture look better. This is especially true for daylight photos where the difference in sensor sizes are not very perceptible to the human eye. Note I will use the term DSLRs to reference all professional/prosumer cameras including mirrorless cameras.

# Computational Photography
It can be said that Google brought about the era of computational photography with it's line of Pixel phones. There are many computational photography techniques that almost all smartphone manufactorers use to make your photos look much better. Below I will describe on some of the techniques and how they compare to modern DSLRs.

## Autofocus
This is standard on both smartphones and DSLRs. Smartphones may use face recognition to assist in focusing however modern mirroless cameras are now able to do it too. 

## Autoexposure
Perfectly nailed on both smartphones and DSLRs

## HDR
HDR stands for high dynamic range. What it does is that it makes bright parts of the images darker and dark parts of the images brighter and gives a closer image to what our eyes actually see.

Unfortunately for this aspect, most DSLRs do not have HDR(or poorly implemented). This results in blown out skies like the image on the left below and underexposed foreground.

To replicate the HDR effect on DSLRs one has to manually bracket the image and merge them in software later(or shoot in raw and edit heavily in post). In many cases replicating HDR in post is not as easy as just pulling up the shadow slider and pulling down the highlight slider in Adobe Lightroom. Many of these smartphones intelligently recognise which part of the image to do these edits such that they look 'natural'.
<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/1.PNG"/>
  <figcaption>Google HDR+ (2014)</figcaption>
</figure>

## Face detection/Local tone mapping and white balance control
This is another feature that is often overlooked. But many smartphone often do face recognition and only apply image edits on the face such that skin tones and facial shadows look very good.

For DSLRs this feature is absolutely none existent. One may get around by using a flash to light your subject but this results in a very unnatural white tone which may or may not match your background.(color gels might solve this issue but might be troublesome to get right)  Using a reflector might get one around this issue but now you need a reflector and possibly an assistant!. This can also be done in post but requires extensive effort of the editor to apply edits locally to the face.
<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/3.jpg"/>
  <figcaption>Example of how a reflector lifts shadows from a person's face casted by the overhead sun.</figcaption>
</figure>
<br>
<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/2.PNG"/>
  <figcaption>Google Pixel 6 (2021). Very good skin tones and shadows despite heavy backlighting.</figcaption>
</figure>

## Night Sight/Mode
Night photos used to be a smartphone's achilles heel because they have very small sensor sizes which tend to have a lot of noise. However modern smartphones have cleverly circumvented this issue by merging multiple photos together to reduce their noise. Google even has an astrophotography mode. And most importantly no tripod! Most of the time even with night mode this still lags behind modern DSLR cameras.

<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/5.PNG"/>
  <figcaption>Google's Night Sight in action (2018).</figcaption>
</figure>
<br>
<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/6.jpg"/>
  <figcaption>Google's Astrophotography mode(2019).</figcaption>
</figure>

## Bokeh
Natural bokeh is almost impossible with a smartphone due to it's small sensor sizes. However advances in machine learning has allowed many of these smartphone to generate fake bokeh which are sometimes hard to tell from the real ones.
<figure>
  <img src="{{ site.baseurl }}/images/computationalPhotography/7.png"/>
  <figcaption>Google's improved portrait mode (2019).</figcaption>
</figure>

# Conclusion
Advances in camera sensor technology has stagnated for years. When will prosumer cameras adopt computational photography features?
I look forward to the day that prosumer cameras have Apple's ProRaw like capabilites which in essence combines the best of 'raw' photography as well as computational photography while maintaining it's flexibility.